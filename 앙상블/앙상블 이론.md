# 1. 앙상블 학습
## 1. 목적
: 여러 분류기를 하나로 연결하여 개별 분류기보다 더 좋은 일반화 성능을 달성하는 것
## 2. 방법
- 여러 분류 알고리즘을 사용 : 다수결 투표(Voting)
- 하나의 분류 알고리즘을 여러번 사용 : 배깅, 부스팅

## 3. 종류
**(1) 다수결 투표**
- 동일한 학습 데이터 사용


**(2) 배깅**
- 알고리즘 수행 마다 다른 학습 데이터 샘플링하여 사용
- 병렬적 처리


**(3) 부스팅**
- 샘플 뽑을 때 이전 모델에서 잘못 분류된 데이터를 재학습에 사용 또는 가중치 사용
- 순차적 처리

# 2. 배깅(Bagging)
## 1. 배깅이란?
- 알고리즘마다 별도의 학습 데이터를 추출(샘플링)하여 모델 구축에 사용
- 부트스트랩(Bootstrap) 사용 (샘플링 시 복원 추출 허용)

![image](https://user-images.githubusercontent.com/70889699/120495891-0fd73580-c3f8-11eb-826d-621c6d64ae0d.png)

## 2. 배깅 : 랜덤 포레스트 (Random Forest)
### 1) 랜덤 포레스트란?
- 배깅의 일종 : 학습 데이터 샘플링
- 단일 분류 알고리즘 : 의사결정나무 사용
- Forest 구축 : 무작위로 예측 변수 선택하여 모델 구축
- 결합 방식 : 투표(분류), 평균화(예측)

![image](https://user-images.githubusercontent.com/70889699/120496140-490fa580-c3f8-11eb-8e7a-5b4a8897879a.png)

### 2) 랜덤 포레스트 분석 절차
1. 새로운 학습 데이터를 만든다.
- 크기가 n이고 d개의 특성 변수를 가지는 학습 데이터
- 부트스트랩을 고려한 n개의 새로운 학습 데이터 구성


2. 새로운 학습 데이터를 이용하여 의사결정나무를 완성한다.
- d개의 특성 변수 중 임의로 k개의 특성 변수를 뽑아 의사결정나무 구성
- k는 일반적으로 루트(d)를 선택함

3. 절차 (1-2)를 M번 반복한다.
- M이 커질수록 성능이 좋아지므로 리소스를 고려하여 가능한 큰 M을 선택, M은 트리의 수

![image](https://user-images.githubusercontent.com/70889699/120496604-a9064c00-c3f8-11eb-90c6-6c0d3b9a1464.png)


# 3. 부스팅 (Boosting)
## 1. 아다부스트 (AdaBoost)
- 순차적으로 weak learner를 적용하여 모델을 구성하는 방법
- weak learner : 임의 분류보다 약간 좋은 모델
- weak learner 추가 시, 전체 학습 데이터 사용하고 잘못 분류된 데이터에 가중치 적용

![image](https://user-images.githubusercontent.com/70889699/120496923-f2ef3200-c3f8-11eb-815e-0072fe2bbca3.png)

## 2. 기울기 부스팅 (GBM, Gradient Boosting Machine)
- 분류, 회귀 문제 모두 사용 가능
- Gradient Boosting = Gradient Descent + Boosting

![image](https://user-images.githubusercontent.com/70889699/120497764-a526f980-c3f9-11eb-8e76-4b48615d2caf.png)


- weak learner 추가를 통해 잔차(residual)를 예측하도록 하는 방법
  - 순차적으로 모델 적용
  - 앞선 모델이 예측하지 못한 차이를 추가모델에서 보상하는 구조


  ![image](https://user-images.githubusercontent.com/70889699/120497811-b112bb80-c3f9-11eb-870c-bdd2d41f0951.png)
  
  ![image](https://user-images.githubusercontent.com/70889699/120497963-d1db1100-c3f9-11eb-9be7-5b1f9bdf2b89.png)

- 손실 함수
  - 회귀 : Squared Loss, Absolute Loss, Huber Loss, Quantile Loss, etc.
  - 분류 : Bernoulli Loss, Adaboost Loss, etc.

- 단점
  - 과적합에 빠지기 쉬움 : 잔차를 모델링 하다 보니, 모델이 노이즈까지 반영
  - 해결책은 Subsampling(전체 데이터의 약 80% 반복 사용), Shrinkage(잔차 영향력 점차 감소), Early Stopping(검증 오차 허용 과적합 방지)

## 3. Light GBM
### 1) 기존 GBM 동작 방식의 문제점
  - 모든 데이터와 특성 변수에 대해 알고리즘을 수행하다보니 비효율적
  - 입력 데이터를 연산하기 효율적으로 변경

### 2) 해결 방법
- GOSS (Gradient-based One-Side Sampling)
  - 모든 데이터를 사용하는 비효울성 해결책
  - Gradients가 큰 데이터 일수록 영향을 크게 미치는 데이터
  - small gradients는 랜덤 드랍, large gradient만 포함

![image](https://user-images.githubusercontent.com/70889699/120498808-79f0da00-c3fa-11eb-83c7-15df121f8a19.png)

- EFB(Exclusive Feature Bundling)
  - 모든 특성 변수를 사용하는 비효율성 해결책
  - 데이터가 매우 sparse 할 경우(e.g. one-hot encoding) EFB를 적용해도 성능 하락이 발생하지 않음
  - 서로 거의 독립인 특성 변수를 묶어서 (Greedy Bundling)
  - 하나의 변수로 표현하는 방법 (Merge Exclusive Features)
  
![image](https://user-images.githubusercontent.com/70889699/120499125-c5a38380-c3fa-11eb-9091-0b226592c65a.png)

![image](https://user-images.githubusercontent.com/70889699/120499170-ce945500-c3fa-11eb-821f-eb701690174b.png)

![image](https://user-images.githubusercontent.com/70889699/120499225-da801700-c3fa-11eb-9081-a97e02735af2.png)











